{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355fd65f-56fc-47fb-aa02-2598f00e21d9",
   "metadata": {},
   "source": [
    "## Course Assignment Instructions\n",
    "You should have Python (version 3.8 or later) and Jupyter Notebook installed to complete this assignment. You will write code in the empty cell/cells below the problem. While most of this will be a programming assignment, some questions will ask you to \"write a few sentences\" in markdown cells. \n",
    "\n",
    "Submission Instructions:\n",
    "\n",
    "Create a labs directory in your personal class repository (e.g., located in your home directory)\n",
    "Clone the class repository\n",
    "Copy this Jupyter notebook file (.ipynb) into your repo/labs directory\n",
    "Make your edits, commit changes, and push to your repository\n",
    "All submissions must be pushed before the due date to avoid late penalties. \n",
    "\n",
    "Labs are graded out of a 100 pts. Each day late is -5. For a max penalty of -50 after 10 days. From there you may submit the lab anytime before the semester ends for a max score of 50.  \n",
    "\n",
    "Lab 2 is due on 2/18/25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffbbc2-9164-463a-895e-da75b2598f51",
   "metadata": {},
   "source": [
    "## Basic Modeling\n",
    "In the 342 class an example was given that considered a variable `x_3` which measured \"criminality\". In this example there are L = 4 levels \"none\", \"infraction\", \"misdemeanor\" and \"felony\". Create a variable `x_3` here with 100 random elements (equally probable). Create it as a nominal (i.e. unordered) factor. Hint: use random.choice from NumPy and Categorical from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce74aa8b-aa8d-4443-917a-dd6846f6b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['felony' 'misdemeanor' 'none' 'felony' 'infraction' 'felony'\n",
      " 'misdemeanor' 'misdemeanor' 'felony' 'felony' 'none' 'none' 'misdemeanor'\n",
      " 'none' 'infraction' 'none' 'misdemeanor' 'none' 'none' 'misdemeanor'\n",
      " 'misdemeanor' 'none' 'infraction' 'felony' 'felony' 'misdemeanor'\n",
      " 'felony' 'felony' 'misdemeanor' 'none' 'felony' 'misdemeanor'\n",
      " 'misdemeanor' 'misdemeanor' 'felony' 'none' 'felony' 'infraction'\n",
      " 'infraction' 'misdemeanor' 'felony' 'none' 'none' 'misdemeanor'\n",
      " 'infraction' 'none' 'felony' 'felony' 'infraction' 'misdemeanor'\n",
      " 'infraction' 'felony' 'none' 'infraction' 'none' 'misdemeanor'\n",
      " 'misdemeanor' 'felony' 'felony' 'none' 'infraction' 'misdemeanor'\n",
      " 'felony' 'none' 'infraction' 'felony' 'infraction' 'misdemeanor' 'none'\n",
      " 'felony' 'infraction' 'none' 'infraction' 'felony' 'misdemeanor' 'felony'\n",
      " 'none' 'misdemeanor' 'misdemeanor' 'misdemeanor' 'misdemeanor' 'felony'\n",
      " 'none' 'felony' 'infraction' 'none' 'misdemeanor' 'none' 'infraction'\n",
      " 'infraction' 'infraction' 'felony' 'felony' 'none' 'felony' 'infraction'\n",
      " 'infraction' 'none' 'felony' 'infraction']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the categories\n",
    "categories = [\"none\", \"infraction\", \"misdemeanor\", \"felony\"]\n",
    "\n",
    "# Generate 100 random elements with equal probability\n",
    "x_3 = np.random.choice(categories, size = 100, replace = True)\n",
    "# Convert to a categorical (nominal) variable in pandas\n",
    "pd.Categorical(x_3, categories = categories, ordered = False)\n",
    "print(x_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6e027-0803-4f80-9fee-361a1ea53d25",
   "metadata": {},
   "source": [
    "Use x_3 to create x_3_bin, a binary feature where 0 is no crime and 1 is any crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670e525b-267b-4b5c-854e-09eb42f33df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# creates a boolean array (True for crime, False for no crime)\n",
    "x_3_bin = (x_3 != \"none\").astype(int)\n",
    "print(x_3_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6105c8e-80eb-47bb-a088-ea567b19df8c",
   "metadata": {},
   "source": [
    "Use `x_3` to create `x_3_ord`, an ordered factor variable. Ensure the proper ordinal ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16e0d1ca-9957-4130-b550-962e3e86c954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['felony', 'misdemeanor', 'none', 'felony', 'infraction', ..., 'infraction', 'infraction', 'none', 'felony', 'infraction']\n",
      "Length: 100\n",
      "Categories (4, object): ['none' < 'infraction' < 'misdemeanor' < 'felony']\n"
     ]
    }
   ],
   "source": [
    "x_3_ord = pd.Categorical(x_3, categories = categories, ordered = True)\n",
    "print(x_3_ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659559c0-9a34-4c38-af71-c6c9910f7ff2",
   "metadata": {},
   "source": [
    "Convert this variable into three binary variables without any information loss and put them into a data matrix. Hint: use column_stack from Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06455be9-05b2-486d-ac5c-08dbad0566ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    is_infraction  is_misdemeanor  is_felony\n",
      "0               0               0          1\n",
      "1               0               1          0\n",
      "2               0               0          0\n",
      "3               0               0          1\n",
      "4               1               0          0\n",
      "..            ...             ...        ...\n",
      "95              1               0          0\n",
      "96              1               0          0\n",
      "97              0               0          0\n",
      "98              0               0          1\n",
      "99              1               0          0\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "x_3_matrix = np.column_stack([\n",
    "    (x_3 == \"infraction\").astype(int),\n",
    "    (x_3 == \"misdemeanor\").astype(int),\n",
    "    (x_3 == \"felony\").astype(int)\n",
    "])\n",
    "\n",
    "x_3_matrix = pd.DataFrame(x_3_matrix, columns = [\"is_infraction\", \"is_misdemeanor\", \"is_felony\"])\n",
    "print(x_3_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225f1e4-57dd-43f4-9c3e-391698dec745",
   "metadata": {},
   "source": [
    "What should the sum of each row be (in English)? Write your answer in the markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdce95-f726-46aa-b3cc-2caa76a25477",
   "metadata": {},
   "source": [
    "0 or 1. 0 if the person did no crime, 1 if the person did one of the types of crime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5770e1-d384-4199-bf8b-f92b6f637c56",
   "metadata": {},
   "source": [
    "Verify that in the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd86eeff-5d4d-4de8-83e9-07de66f220ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    75\n",
      "0    25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "row_sum = x_3_matrix.sum(axis = 1)\n",
    "print(row_sum.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdfff3-9476-46d7-acc2-8fd13bfe7eed",
   "metadata": {},
   "source": [
    " How should the column sum look (in English)? Write your answer in the markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aed132-b84d-4084-b242-eda992feb249",
   "metadata": {},
   "source": [
    "The sum of each row should be around 25 as we used random to assign the categories which should disperse them evenely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319576be-978e-4130-8c16-82206d42558e",
   "metadata": {},
   "source": [
    "Verify that in the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2346133a-e7be-4964-8c5e-1d202c5218b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_infraction     21\n",
      "is_misdemeanor    25\n",
      "is_felony         29\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_sum = x_3_matrix.sum(axis = 0)\n",
    "print(col_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cf75f-aee2-47eb-b6c7-7ef9067e0721",
   "metadata": {},
   "source": [
    "Generate a matrix with 100 rows where the first column is realization from a normal with mean 17 and variance 38, the second column is uniform between -10 and 10, the third column is poisson with mean 6, the fourth column is exponential with lambda of 9, the fifth column is binomial with n = 20 and p = 0.12 and the sixth column is a binary variable with exactly 24% 1's dispersed randomly. Name the rows the entries of the `fake_first_names` vector. You will need to use Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67db4b39-b1d9-4848-a330-1f11c6cacbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Normal   Uniform  Poisson  Exponential  Binomial  Binary\n",
      "Sophia     15.486595  5.491942        7     0.042153         2       0\n",
      "Emma       16.812618 -1.689414        5     0.164838         2       0\n",
      "Olivia     19.247926 -2.364159        5     0.364949         2       0\n",
      "Ava        12.173202  8.585097        4     0.078225         3       0\n",
      "Mia        23.521994 -2.141151        6     0.019589         1       0\n",
      "...              ...       ...      ...          ...       ...     ...\n",
      "Christian  26.065681  0.708227        8     0.258644         2       0\n",
      "Andrew     18.380533 -1.388724        6     0.003340         1       1\n",
      "Brayden    15.980011 -0.230347        6     0.068276         3       1\n",
      "John       15.749537 -0.708023        8     0.013984         2       0\n",
      "Lincoln     9.904255 -7.295067        2     0.018377         5       0\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Number of rows\n",
    "n = 100\n",
    "\n",
    "# Assign row names (index) from fake_first_names\n",
    "fake_first_names = [\n",
    "    \"Sophia\", \"Emma\", \"Olivia\", \"Ava\", \"Mia\", \"Isabella\", \"Riley\", \n",
    "    \"Aria\", \"Zoe\", \"Charlotte\", \"Lily\", \"Layla\", \"Amelia\", \"Emily\", \n",
    "    \"Madelyn\", \"Aubrey\", \"Adalyn\", \"Madison\", \"Chloe\", \"Harper\", \n",
    "    \"Abigail\", \"Aaliyah\", \"Avery\", \"Evelyn\", \"Kaylee\", \"Ella\", \"Ellie\", \n",
    "    \"Scarlett\", \"Arianna\", \"Hailey\", \"Nora\", \"Addison\", \"Brooklyn\", \n",
    "    \"Hannah\", \"Mila\", \"Leah\", \"Elizabeth\", \"Sarah\", \"Eliana\", \"Mackenzie\", \n",
    "    \"Peyton\", \"Maria\", \"Grace\", \"Adeline\", \"Elena\", \"Anna\", \"Victoria\", \n",
    "    \"Camilla\", \"Lillian\", \"Natalie\", \"Jackson\", \"Aiden\", \"Lucas\", \n",
    "    \"Liam\", \"Noah\", \"Ethan\", \"Mason\", \"Caden\", \"Oliver\", \"Elijah\", \n",
    "    \"Grayson\", \"Jacob\", \"Michael\", \"Benjamin\", \"Carter\", \"James\", \n",
    "    \"Jayden\", \"Logan\", \"Alexander\", \"Caleb\", \"Ryan\", \"Luke\", \"Daniel\", \n",
    "    \"Jack\", \"William\", \"Owen\", \"Gabriel\", \"Matthew\", \"Connor\", \"Jayce\", \n",
    "    \"Isaac\", \"Sebastian\", \"Henry\", \"Muhammad\", \"Cameron\", \"Wyatt\", \n",
    "    \"Dylan\", \"Nathan\", \"Nicholas\", \"Julian\", \"Eli\", \"Levi\", \"Isaiah\", \n",
    "    \"Landon\", \"David\", \"Christian\", \"Andrew\", \"Brayden\", \"John\", \n",
    "    \"Lincoln\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame with the specified distributions\n",
    "X = pd.DataFrame({\n",
    "    \"Normal\": np.random.normal(loc = 17, scale = np.sqrt(38), size = n),  # Normal(17, variance 38)\n",
    "    \"Uniform\": np.random.uniform(low = -10, high = 10, size = n),         # Uniform(-10, 10)\n",
    "    \"Poisson\": np.random.poisson(6, size = n),                            # Poisson(6)\n",
    "    \"Exponential\": np.random.exponential(1/9, size = n),                  # Exponential(λ=9)\n",
    "    \"Binomial\": np.random.binomial(n = 20, p = .12, size = n),            # Binomial(n=20, p=0.12)\n",
    "    \"Binary\": np.random.permutation([1] * int(n * .24) + [0] * int(n * .76))  # 24% 1s, shuffled\n",
    "})\n",
    "X.index = fake_first_names[:n]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4816dd-9c9f-4b42-9faf-56c2b450b4c0",
   "metadata": {},
   "source": [
    "Create a data frame of the same data as above except make the binary variable a factor \"DOMESTIC\" vs \"FOREIGN\" for 0 and 1 respectively. In Rstudio you used the `View` function to ensure this worked as desired. In python use .head() on the DataFrame. I recommend creating a copy of the DataFrame and then using the .replace in conjunction with .astype(\"category\") to make the binary variable a factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b71b1aa-e16a-4132-b271-a105a9b3aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Uniform</th>\n",
       "      <th>Poisson</th>\n",
       "      <th>Exponential</th>\n",
       "      <th>Binomial</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sophia</th>\n",
       "      <td>15.486595</td>\n",
       "      <td>5.491942</td>\n",
       "      <td>7</td>\n",
       "      <td>0.042153</td>\n",
       "      <td>2</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emma</th>\n",
       "      <td>16.812618</td>\n",
       "      <td>-1.689414</td>\n",
       "      <td>5</td>\n",
       "      <td>0.164838</td>\n",
       "      <td>2</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olivia</th>\n",
       "      <td>19.247926</td>\n",
       "      <td>-2.364159</td>\n",
       "      <td>5</td>\n",
       "      <td>0.364949</td>\n",
       "      <td>2</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ava</th>\n",
       "      <td>12.173202</td>\n",
       "      <td>8.585097</td>\n",
       "      <td>4</td>\n",
       "      <td>0.078225</td>\n",
       "      <td>3</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mia</th>\n",
       "      <td>23.521994</td>\n",
       "      <td>-2.141151</td>\n",
       "      <td>6</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Normal   Uniform  Poisson  Exponential  Binomial    Binary\n",
       "Sophia  15.486595  5.491942        7     0.042153         2  Domestic\n",
       "Emma    16.812618 -1.689414        5     0.164838         2  Domestic\n",
       "Olivia  19.247926 -2.364159        5     0.364949         2  Domestic\n",
       "Ava     12.173202  8.585097        4     0.078225         3  Domestic\n",
       "Mia     23.521994 -2.141151        6     0.019589         1  Domestic"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert matrix DataFrame to categorical for the binary variable\n",
    "# Make a copy to keep X unchanged\n",
    "X_copy = X.copy() \n",
    "\n",
    "# Convert binary column (6th column) to categorical labels\n",
    "X_copy[\"Binary\"] = X_copy[\"Binary\"].replace({0: \"Domestic\", 1: \"Foreign\"}).astype(\"category\")\n",
    "\n",
    "# Display first few rows\n",
    "X_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd05e5-4162-407c-a4ee-d7b16f0ccf74",
   "metadata": {},
   "source": [
    "Print out a table of the binary variable. Then print out the proportions of \"DOMESTIC\" vs \"FOREIGN\". Pandas DataFrames has a .value_count() feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ae57f3-562f-4e73-8eea-40361c93d17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binary\n",
       "Domestic    0.76\n",
       "Foreign     0.24\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_copy[\"Binary\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d5862-6f78-436e-97ec-f98ab801299e",
   "metadata": {},
   "source": [
    "Print out a summary of the whole dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68f0156a-db34-4bda-997e-e7c72ed16ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Normal     Uniform     Poisson  Exponential    Binomial\n",
      "count  100.000000  100.000000  100.000000   100.000000  100.000000\n",
      "mean    16.825248    1.304737    5.910000     0.112094    2.130000\n",
      "std      6.832460    5.701908    2.127715     0.116061    1.440083\n",
      "min      1.756510   -9.499054    1.000000     0.000814    0.000000\n",
      "25%     12.761071   -2.920130    4.750000     0.036676    1.000000\n",
      "50%     16.943084    2.028144    6.000000     0.067879    2.000000\n",
      "75%     20.577845    5.964783    7.250000     0.147208    3.000000\n",
      "max     34.793817    9.660658   10.000000     0.575841    6.000000\n",
      "Binary\n",
      "Domestic    76\n",
      "Foreign     24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_copy.describe())\n",
    "print(X_copy[\"Binary\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb557a15-731f-442f-88d7-c89c34d8e7a4",
   "metadata": {},
   "source": [
    "## Dataframe creation\n",
    "Imagine you are running an experiment with many manipulations. You have 14 levels in the variable \"treatment\" with levels a, b, c, etc. For each of those manipulations you have 3 submanipulations in a variable named \"variation\" with levels A, B, C. Then you have \"gender\" with levels M / F. Then you have \"generation\" with levels Boomer, GenX, Millenial. Then you will have 6 runs per each of these groups. In each set of 6 you will need to select a name without duplication from the appropriate set of names (from the last question). Create a data frame with columns treatment, variation, gender, generation, name and y that will store all the unique unit information in this experiment. Leave y empty because it will be measured as the experiment is executed. In Rstudio you used `rep` function using the `times` argument. For python use np.tile, and np.repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8e615f0-9abe-47ed-8be4-898d653b54a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   orig_index treatment variation gender generation      name   y\n",
      "0           0         a         A      M     Boomer  Marjorie NaN\n",
      "1           1         a         A      M     Boomer       Kay NaN\n",
      "2           2         a         A      M     Boomer    Dianne NaN\n",
      "3           3         a         A      M     Boomer   Shirley NaN\n",
      "4           4         a         A      M     Boomer   Mildred NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shana\\AppData\\Local\\Temp\\ipykernel_27344\\1054633614.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[\"name\"] = df.groupby([\"treatment\", \"variation\", \"gender\", \"generation\"], group_keys=False).apply(assign_names).explode().reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_index</th>\n",
       "      <th>treatment</th>\n",
       "      <th>variation</th>\n",
       "      <th>gender</th>\n",
       "      <th>generation</th>\n",
       "      <th>name</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Marjorie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Kay</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Dianne</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Shirley</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>Mildred</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>1507</td>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Gabriel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>1508</td>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Evan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>1509</td>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Austin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1510</td>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Casey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1511</td>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>Christian</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_index treatment variation gender generation       name   y\n",
       "0              0         a         A      M     Boomer   Marjorie NaN\n",
       "1              1         a         A      M     Boomer        Kay NaN\n",
       "2              2         a         A      M     Boomer     Dianne NaN\n",
       "3              3         a         A      M     Boomer    Shirley NaN\n",
       "4              4         a         A      M     Boomer    Mildred NaN\n",
       "...          ...       ...       ...    ...        ...        ...  ..\n",
       "1507        1507         n         C      F  Millenial    Gabriel NaN\n",
       "1508        1508         n         C      F  Millenial       Evan NaN\n",
       "1509        1509         n         C      F  Millenial     Austin NaN\n",
       "1510        1510         n         C      F  Millenial      Casey NaN\n",
       "1511        1511         n         C      F  Millenial  Christian NaN\n",
       "\n",
       "[1512 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define categories\n",
    "treatments = list(\"abcdefghijklmn\")\n",
    "variations = list(\"ABC\")\n",
    "genders = [\"M\", \"F\"]\n",
    "generations = [\"Boomer\", \"GenX\", \"Millenial\"]\n",
    "\n",
    "\n",
    "# Define name sets\n",
    "name_sets = {\n",
    "    \"M\": {\n",
    "        \"Boomer\": [\"Theodore\", \"Bernard\", \"Gene\", \"Herbert\", \"Ray\", \"Tom\", \"Lee\", \"Alfred\", \"Leroy\", \"Eddie\"],\n",
    "        \"GenX\": [\"Marc\", \"Jamie\", \"Greg\", \"Darryl\", \"Tim\", \"Dean\", \"Jon\", \"Chris\", \"Troy\", \"Jeff\"],\n",
    "        \"Millenial\": [\"Zachary\", \"Dylan\", \"Christian\", \"Wesley\", \"Seth\", \"Austin\", \"Gabriel\", \"Evan\", \"Casey\", \"Luis\"]\n",
    "    },\n",
    "    \"F\": {\n",
    "        \"Boomer\": [\"Gloria\", \"Joan\", \"Dorothy\", \"Shirley\", \"Betty\", \"Dianne\", \"Kay\", \"Marjorie\", \"Lorraine\", \"Mildred\"],\n",
    "        \"GenX\": [\"Tracy\", \"Dawn\", \"Tina\", \"Tammy\", \"Melinda\", \"Tamara\", \"Tracey\", \"Colleen\", \"Sherri\", \"Heidi\"],\n",
    "        \"Millenial\": [\"Samantha\", \"Alexis\", \"Brittany\", \"Lauren\", \"Taylor\", \"Bethany\", \"Latoya\", \"Candice\", \"Brittney\", \"Cheyenne\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Create experiment dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"treatment\": np.repeat(treatments, len(variations) * len(genders) * len(generations) * 6),\n",
    "    \"variation\": np.tile(np.repeat(variations, len(genders) * len(generations) * 6), len(treatments)),\n",
    "    \"gender\": np.tile(np.repeat(genders, len(generations) * 6), len(treatments) * len(variations)),\n",
    "    \"generation\": np.tile(np.repeat(generations, 6), len(treatments) * len(variations) * len(genders))\n",
    "})\n",
    "\n",
    "# Add a unique identifier to preserve the original order\n",
    "df = df.reset_index().rename(columns={'index': 'orig_index'})\n",
    "\n",
    "# Function to assign unique names per group\n",
    "def assign_names(group):\n",
    "    gender_val = group[\"gender\"].iloc[0]  # Extract gender\n",
    "    generation_val = group[\"generation\"].iloc[0]  # Extract generation\n",
    "    return np.random.choice(name_sets[gender_val][generation_val], 6, replace=False)\n",
    "\n",
    "# Apply function to assign names\n",
    "df[\"name\"] = df.groupby([\"treatment\", \"variation\", \"gender\", \"generation\"], group_keys=False).apply(assign_names).explode().reset_index(drop=True)\n",
    "\n",
    "# Add empty column y\n",
    "df[\"y\"] = np.nan\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a1af36-87fe-4200-a40c-2aeb568a1e6b",
   "metadata": {},
   "source": [
    "Now that you've done it with the np.tile and np.repeat, Try doing this by importing product from the itertools module. This will be analogous to using `expand.grid` function from Rstudio. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e35a7-6eec-4434-b88a-7220c503d18e",
   "metadata": {},
   "source": [
    "| **R Function** | **Python Equivalent** |\n",
    "|--------------|-----------------|\n",
    "| `rep(x, times=n)` | `np.repeat(x, n)` |\n",
    "| `rep(x, each=n)` | `np.tile(np.repeat(x, n), times)` |\n",
    "| `rep(x, length.out=n)` | `np.resize(x, n)` |\n",
    "| `expand.grid()` | `itertools.product()` |\n",
    "\n",
    "| **R Function** | **Python Equivalent** | **Use Case** |\n",
    "|--------------|-----------------|-----------|\n",
    "| `rep(x, times=n)` | `np.repeat(x, n)` | Repeat each element **`n` times** in order |\n",
    "| `rep(x, each=n)` | `np.tile(x, n)` | Repeat the full sequence **`n` times** |\n",
    "| `rep(x, length.out=n)` | `np.resize(x, n)` | Repeat `x` but **truncate** or **expand** to length `n` |\n",
    "\n",
    "**`expand.grid()` → `itertools.product()`** for generating **all combinations**  \n",
    "**`rep(..., each=n)` → `np.repeat()`** for **repeating values in order**  \n",
    "**`rep(..., times=n)` → `np.tile()`** for **cycling through values**  \n",
    "**`Combination of `np.repeat()` and `np.tile()`** replaces **nested `rep()`** in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8997381c-d4d5-45ae-86dc-7f1c5ed38705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  treatment variation gender generation  run      name   y\n",
      "0         a         A      M     Boomer    1       Lee NaN\n",
      "1         a         A      M     Boomer    2       Tom NaN\n",
      "2         a         A      M     Boomer    3     Eddie NaN\n",
      "3         a         A      M     Boomer    4   Herbert NaN\n",
      "4         a         A      M     Boomer    5  Theodore NaN\n",
      "Total rows: 1512 (Expected: 1512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shana\\AppData\\Local\\Temp\\ipykernel_27344\\2515925502.py:36: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df[\"name\"] = df.groupby([\"treatment\", \"variation\", \"gender\", \"generation\"], sort = False, group_keys = False).apply(assign_names).explode().reset_index(drop = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>variation</th>\n",
       "      <th>gender</th>\n",
       "      <th>generation</th>\n",
       "      <th>run</th>\n",
       "      <th>name</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>1</td>\n",
       "      <td>Lee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>2</td>\n",
       "      <td>Tom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>3</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>4</td>\n",
       "      <td>Herbert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>Boomer</td>\n",
       "      <td>5</td>\n",
       "      <td>Theodore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>2</td>\n",
       "      <td>Alexis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>3</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>4</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>5</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>n</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>Millenial</td>\n",
       "      <td>6</td>\n",
       "      <td>Brittany</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     treatment variation gender generation  run      name   y\n",
       "0            a         A      M     Boomer    1       Lee NaN\n",
       "1            a         A      M     Boomer    2       Tom NaN\n",
       "2            a         A      M     Boomer    3     Eddie NaN\n",
       "3            a         A      M     Boomer    4   Herbert NaN\n",
       "4            a         A      M     Boomer    5  Theodore NaN\n",
       "...        ...       ...    ...        ...  ...       ...  ..\n",
       "1507         n         C      F  Millenial    2    Alexis NaN\n",
       "1508         n         C      F  Millenial    3  Samantha NaN\n",
       "1509         n         C      F  Millenial    4    Lauren NaN\n",
       "1510         n         C      F  Millenial    5    Taylor NaN\n",
       "1511         n         C      F  Millenial    6  Brittany NaN\n",
       "\n",
       "[1512 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define categories\n",
    "treatments = list(\"abcdefghijklmn\")\n",
    "variations = list(\"ABC\")\n",
    "genders = [\"M\", \"F\"]\n",
    "generations = [\"Boomer\", \"GenX\", \"Millenial\"]\n",
    "runs_per_group = 6\n",
    "# Define name sets\n",
    "name_sets = {\n",
    "    \"M\": {\n",
    "        \"Boomer\": [\"Theodore\", \"Bernard\", \"Gene\", \"Herbert\", \"Ray\", \"Tom\", \"Lee\", \"Alfred\", \"Leroy\", \"Eddie\"],\n",
    "        \"GenX\": [\"Marc\", \"Jamie\", \"Greg\", \"Darryl\", \"Tim\", \"Dean\", \"Jon\", \"Chris\", \"Troy\", \"Jeff\"],\n",
    "        \"Millenial\": [\"Zachary\", \"Dylan\", \"Christian\", \"Wesley\", \"Seth\", \"Austin\", \"Gabriel\", \"Evan\", \"Casey\", \"Luis\"]\n",
    "    },\n",
    "    \"F\": {\n",
    "        \"Boomer\": [\"Gloria\", \"Joan\", \"Dorothy\", \"Shirley\", \"Betty\", \"Dianne\", \"Kay\", \"Marjorie\", \"Lorraine\", \"Mildred\"],\n",
    "        \"GenX\": [\"Tracy\", \"Dawn\", \"Tina\", \"Tammy\", \"Melinda\", \"Tamara\", \"Tracey\", \"Colleen\", \"Sherri\", \"Heidi\"],\n",
    "        \"Millenial\": [\"Samantha\", \"Alexis\", \"Brittany\", \"Lauren\", \"Taylor\", \"Bethany\", \"Latoya\", \"Candice\", \"Brittney\", \"Cheyenne\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate all unique combinations (equivalent to expand.grid in R)\n",
    "df = pd.DataFrame(product(treatments, variations, genders, generations, range(1, runs_per_group + 1)),\n",
    "                  columns=[\"treatment\", \"variation\", \"gender\", \"generation\", \"run\"])\n",
    "\n",
    "\n",
    "\n",
    "# Function to assign unique names per gender-generation group\n",
    "def assign_names(group):\n",
    "    gender = group[\"gender\"].iloc[0]\n",
    "    generation = group[\"generation\"].iloc[0]\n",
    "    return np.random.choice(name_sets[gender][generation], size = len(group), replace = False)\n",
    "    \n",
    "# Apply function ensuring each group gets 6 names\n",
    "df[\"name\"] = df.groupby([\"treatment\", \"variation\", \"gender\", \"generation\"], sort = False, group_keys = False).apply(assign_names).explode().reset_index(drop = True)\n",
    "\n",
    "# Add an empty column for y (to be measured later)\n",
    "df[\"y\"] = np.nan\n",
    "\n",
    "# Print first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Verify the number of rows (should be 1512)\n",
    "print(f\"Total rows: {len(df)} (Expected: {14 * 3 * 2 * 3 * 6})\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5d2ba-4e03-40b8-a65b-2730add003cf",
   "metadata": {},
   "source": [
    "## Basic Binary Classification Modeling\n",
    "\n",
    "Load the famous `iris` data frame into the namespace. In Rstudio you used the `skim` function from the package `skimr` to provide a summary of the columns. In python we will use df.describe() and the ProfileReport from the ydata-profiling package. The `iris` data set is not available in base python, but we can get this data from the sklearn package. Write a few descriptive sentences about the distributions using the code below in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8e98a-8bca-4fed-8bdb-e38e3af138f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install scikit-learn by uncommenting the code below\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a425f989-a578-4f22-b22f-6a78037cdac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install ydata-profile by uncommenting the code below\n",
    "%pip install -U ydata-profiling[notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e432f-4c74-402e-8ffd-94086acea991",
   "metadata": {},
   "source": [
    "### **Comparing the `iris` Dataset in R vs Python**\n",
    "| Feature  | **R (`datasets::iris`)**  | **Python (`sklearn.datasets.load_iris()`)**  |\n",
    "|----------|-------------------------|--------------------------------|\n",
    "| **Total Rows**  | 150 | 150 |\n",
    "| **Columns (Features)** | 5 (`Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width`, `Species`) | 5 (`sepal length (cm)`, `sepal width (cm)`, `petal length (cm)`, `petal width (cm)`, `species`) |\n",
    "| **Species Encoding**  | `\"setosa\"`, `\"versicolor\"`, `\"virginica\"` (Categorical Factor) | `0` (setosa), `1` (versicolor), `2` (virginica) (Numerical Encoding) |\n",
    "| **Data Type for Species** | Factor (Categorical) | Integer (0,1,2) |\n",
    "| **Data Loading Method** | `data(iris)` (built-in dataset) | `datasets.load_iris()` (from `sklearn`) |\n",
    "\n",
    "### **Key Differences**\n",
    "- **Species Encoding:**  \n",
    "  - **R uses categorical factor labels (`setosa`, `versicolor`, `virginica`).**  \n",
    "  - **Python (`sklearn`) encodes species numerically as `0`, `1`, and `2`.**\n",
    "- **Column Names:**  \n",
    "  - **R:** `Sepal.Length`, `Sepal.Width`, etc.  \n",
    "  - **Python:** `sepal length (cm)`, `sepal width (cm)`, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee083aa6-2ddd-42c5-9fda-69f5109800d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import ydata_profiling  \n",
    "\n",
    "# Load the famous Iris dataset\n",
    "Iris = datasets.load_iris()\n",
    "df_iris = pd.DataFrame(Iris.data, columns = Iris.feature_names)\n",
    "\n",
    "df_iris[\"species\"] = Iris.target\n",
    "print(df_iris.describe())\n",
    "\n",
    "profile = ydata_profiling.ProfileReport(df_iris, title = \"iris summary\", explorative = True)\n",
    "# Generate the profiling report (Uncomment to generate HTML file)\n",
    "profile.to_file(\"iris_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd248b90-f54e-469f-9136-4c7bef72170a",
   "metadata": {},
   "source": [
    "TO-DO: describe this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa24ea7-7952-4619-8a64-bf532fed741e",
   "metadata": {},
   "source": [
    "The iris dataset has 150 observations and 5 variables: sepal length, sepal width, petal length, petal width and species\n",
    "sepal width, sepal length, petal width and petal length are numerical observations while species is categorical with 3 levels.\n",
    "There is also no missing data in this dataset.\n",
    "The minimum sepal length is 4.3 and the max is 7.9 with a mean of 5.843\n",
    "The minimum sepal width is 2 and the max is 4.4 with a mean of 3.057\n",
    "The minimum petal length is 1 and the max is 6.9 with a mean of 3.758\n",
    "The minimum petal width is .1 and the max is 2.5 with a mean of 1.199\n",
    "There are 3 species and each one's count is 50\n",
    "Our goal is to be able to perdict if it is species 0 or 1 using only the sepal length. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9410a-f7f6-4fdb-a18c-722947bfc29b",
   "metadata": {},
   "source": [
    "The outcome / label / response is `Species`. This is what we will be trying to predict. However, we only care about binary classification between \"setosa\" and \"versicolor\" for the purposes of this exercise. Thus the first order of business is to drop one class. Let's drop the data for the level \"virginica\" from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2614d6-1cdc-44d9-a086-2c0cd62a42ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter out \"virginica\" from the dataset\n",
    "df_iris_binary = df_iris[df_iris[\"species\"] != 2].copy()\n",
    "print(df_iris_binary[\"species\"].unique())\n",
    "df_iris_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf18a6b5-ba05-47ef-9753-62802ce454f5",
   "metadata": {},
   "source": [
    "Now create a vector `y` that is length the number of remaining rows in the data frame whose entries are 0 if \"setosa\" and 1 if \"versicolor\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8332c-156d-46a2-a936-137d41786e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target vector `y` (0 for setosa, 1 for versicolor)\n",
    "y = (df_iris_binary[\"species\"] == 1).astype(int)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb64b66-f9de-4c71-9772-6a9e6eb92adc",
   "metadata": {},
   "source": [
    "Write a function `mode` returning the sample mode of a vector of numeric values. Use np.random.choice from NumPy and import Counter from the collections module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b464e6b-d637-437c-acba-278cd9a2f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Define mode function\n",
    "def mode(v):\n",
    "    return Counter(v).most_common(1)[0][0]\n",
    "\n",
    "# Test with a random sample (equivalent to `sample(letters, 1000, replace=TRUE)`)\n",
    "sample_data = np.random.choice(list(\"abcdefghijklmnopqrstuvwxyz\"), 1000, replace=True)\n",
    "print(\"Mode of sample letters:\", mode(sample_data))\n",
    "\n",
    "# Test with binary target vector `y`\n",
    "print(\"Mode of y:\", mode(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2637b47-66d9-4f86-9615-33e45d34a4ac",
   "metadata": {},
   "source": [
    "Fit a threshold model to `y` using the feature `Sepal.Length`. Write your own code to do this. What is the estimated value of the threshold parameter? Save the threshold value as `threshold`. Hint: use np.zeros and np.sum from Numpy. You will need to use a for loop using the range() function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c828658-e5c0-45a7-af97-38804d222777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant data\n",
    "sepal_length = df_iris_binary[\"sepal length (cm)\"].values  # Feature\n",
    "y_values = y.values  # Target labels (0 or 1)\n",
    "n = len(sepal_length)  # Number of samples\n",
    "\n",
    "# Initialize matrix to store threshold values and corresponding error counts\n",
    "num_errors_by_parameter = np.zeros((n, 2))\n",
    "\n",
    "# Loop over all possible threshold values\n",
    "for i in range(n):\n",
    "    threshold = sepal_length[i]  # Set current threshold\n",
    "    num_errors = np.sum((sepal_length > threshold) != y_values)  # Count classification errors\n",
    "    num_errors_by_parameter[i] = [threshold, num_errors]  # Store values\n",
    "\n",
    "# Sort by number of errors\n",
    "num_errors_by_parameter = num_errors_by_parameter[num_errors_by_parameter[:, 1].argsort()]\n",
    "\n",
    "# Get the threshold with the least number of errors\n",
    "best_threshold = num_errors_by_parameter[0, 0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Optimal threshold for classification: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251490a-2bd4-41db-a4d5-439fe0880944",
   "metadata": {},
   "source": [
    "What is the total number of errors this model makes? This requires a couple of minor modifications to the previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe81982-cf59-49d0-b7b9-579b7f639124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant data\n",
    "sepal_length = df_iris_binary[\"sepal length (cm)\"].values  # Feature\n",
    "y_values = y.values  # Target labels (0 or 1)\n",
    "n = len(sepal_length)  # Number of samples\n",
    "\n",
    "# Initialize matrix to store threshold values and corresponding error counts\n",
    "num_errors_by_parameter = np.zeros((n, 2))\n",
    "total_errors = 0\n",
    "# Loop over all possible threshold values\n",
    "for i in range(n):\n",
    "    threshold = sepal_length[i]  # Set current threshold\n",
    "    num_errors = np.sum((sepal_length > threshold) != y_values)  # Count classification errors\n",
    "    \n",
    "    # Store threshold and corresponding errors\n",
    "    num_errors_by_parameter[i] = [threshold, num_errors]\n",
    "    \n",
    "    # Accumulate total errors across all thresholds\n",
    "    total_errors += num_errors\n",
    "\n",
    "# Sort by number of errors to find the best threshold\n",
    "num_errors_by_parameter = num_errors_by_parameter[num_errors_by_parameter[:, 1].argsort()]\n",
    "best_threshold = num_errors_by_parameter[0, 0]  # Best threshold with the least errors\n",
    "\n",
    "# Print results\n",
    "print(f\"Optimal threshold for classification: {best_threshold}\")\n",
    "print(f\"Total number of errors across all thresholds: {total_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1454817-710a-41be-981e-be1966366b1c",
   "metadata": {},
   "source": [
    "Does the threshold model's performance make sense given the following summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40fb82f-80c7-4b13-b242-298777096815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best threshold found earlier\n",
    "print(f\"Optimal threshold for classification: {best_threshold}\")\n",
    "\n",
    "# Summary statistics for setosa and versicolor Sepal.Length\n",
    "setosa_summary = df_iris_binary[df_iris_binary[\"species\"] == 0][\"sepal length (cm)\"].describe()\n",
    "versicolor_summary = df_iris_binary[df_iris_binary[\"species\"] == 1][\"sepal length (cm)\"].describe()\n",
    "\n",
    "# Print summaries\n",
    "print(\"\\nSummary statistics for Setosa Sepal Length:\")\n",
    "print(setosa_summary)\n",
    "\n",
    "print(\"\\nSummary statistics for Versicolor Sepal Length:\")\n",
    "print(versicolor_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22f16a3-7780-49d8-a14d-614a87eb2d8f",
   "metadata": {},
   "source": [
    "TO-DO: Write your answer here in English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901db688-69b7-4362-9e05-93ad49d6843d",
   "metadata": {},
   "source": [
    "Yes, the threshold is in middle of the mean's of the setosa and versicolor sepal length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df601bb-9732-4bb9-b7a7-a24e28987d2e",
   "metadata": {},
   "source": [
    "Create the function `g` explicitly that can predict `y` from `x` being a new `Sepal.Length`. Hint: use np.where from Numpy ... this can also be down using a lambda function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c890a3-8d19-4867-a73a-d51a69708597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function `g` for threshold-based prediction\n",
    "def g(x):\n",
    "    return np.where(x > best_threshold, 1, 0)\n",
    "\n",
    "test_val = 4\n",
    "g(test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89175c-c175-44b4-96d9-e4ddb91c9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x: np.where(x > best_threshold, 1, 0)\n",
    "\n",
    "g(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
